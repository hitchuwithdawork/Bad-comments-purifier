{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO5N5W7wbTyL"
      },
      "source": [
        "## 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t_g7ZlTpbNxe",
        "outputId": "e9a4ae07-fff7-4d83-e20e-d5dad84fd72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3CdWswqcbNxe",
        "outputId": "6ea86035-53f4-4f53-b7e2-2f2660ed53b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.9.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VICmpaTzbNxf"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7EvPLGFTbNxg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import tqdm as tqdm\n",
        "\n",
        "from transformers import(\n",
        "    AutoModel,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    default_data_collator,\n",
        "    EarlyStoppingCallback,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    get_constant_schedule,\n",
        "    AdamW\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Mon1ZzekbNxg",
        "outputId": "0102ab6f-7fae-450c-a994-8d4881ae2447"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjchoi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58AlIH3hbYk2"
      },
      "source": [
        "## ReadCsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6IdWec5rLH8R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame()\n",
        "for i in range(1,7):\n",
        "    temp_data = pd.read_csv(f'https://raw.githubusercontent.com/cmj-dev/groomProject/main/data/gen_train_data_{i}.csv')\n",
        "    data = pd.concat([data,temp_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bpjoDoHP-UYP",
        "outputId": "6470d348-9605-43d3-8aab-e16184e20b55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-86611320-6f15-4a37-b22c-9d4a3ea281c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masked</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>쉴드 아니라 국가가해준거야.</td>\n",
              "      <td>쉴드가 아니라 국가가 면제해준거야.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>짐승 들어ㅋㅋ</td>\n",
              "      <td>짐승입장도 들어봐야지ㅋㅋ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>깐라고기까지</td>\n",
              "      <td>깐부라고 부르기까지 하다니</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>어머니 간 해 주기 싫어서 도망쳤다고...?</td>\n",
              "      <td>어머니 간 이식 해 주기 싫어서 도망쳤다고...?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>##한 기념 내가 사 줄게</td>\n",
              "      <td>고생한 기념으로 내가 저녁 사 줄게</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12334</th>\n",
              "      <td>일을 해서 숙련도가 좋겠지?</td>\n",
              "      <td>그동안 일을 꾸준히 해서 숙련도가 좋겠지?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12335</th>\n",
              "      <td>당구장에서 알바하는데 아저씨들이 나중에 밥한끼사준다면서알려달라고 그래 ; ;</td>\n",
              "      <td>당구장에서 알바하는데 아저씨들이 나중에 밥한끼사준다면서 번호알려달라고 그래;;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12336</th>\n",
              "      <td>ㅠㅠ눈빛도 완전 그윽하게 쳐다보는데 그만둘 그냥..</td>\n",
              "      <td>ㅠㅠ눈빛도 완전 그윽하게 쳐다보는데 그만둘까봐 그냥..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12337</th>\n",
              "      <td>근데니까 다른인 친구로 속이더라</td>\n",
              "      <td>근데 누구냐니까 다른 남자인 친구로 속이더라</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12338</th>\n",
              "      <td>왜그래.. 너도에겐 엄아라고</td>\n",
              "      <td>왜그래.. 너도 누군가에겐 엄친아라고</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12339 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86611320-6f15-4a37-b22c-9d4a3ea281c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86611320-6f15-4a37-b22c-9d4a3ea281c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86611320-6f15-4a37-b22c-9d4a3ea281c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           masked  \\\n",
              "0                                 쉴드 아니라 국가가해준거야.   \n",
              "1                                         짐승 들어ㅋㅋ   \n",
              "2                                          깐라고기까지   \n",
              "3                        어머니 간 해 주기 싫어서 도망쳤다고...?   \n",
              "4                                  ##한 기념 내가 사 줄게   \n",
              "...                                           ...   \n",
              "12334                             일을 해서 숙련도가 좋겠지?   \n",
              "12335  당구장에서 알바하는데 아저씨들이 나중에 밥한끼사준다면서알려달라고 그래 ; ;   \n",
              "12336                ㅠㅠ눈빛도 완전 그윽하게 쳐다보는데 그만둘 그냥..   \n",
              "12337                           근데니까 다른인 친구로 속이더라   \n",
              "12338                             왜그래.. 너도에겐 엄아라고   \n",
              "\n",
              "                                          original  \n",
              "0                              쉴드가 아니라 국가가 면제해준거야.  \n",
              "1                                    짐승입장도 들어봐야지ㅋㅋ  \n",
              "2                                   깐부라고 부르기까지 하다니  \n",
              "3                      어머니 간 이식 해 주기 싫어서 도망쳤다고...?  \n",
              "4                              고생한 기념으로 내가 저녁 사 줄게  \n",
              "...                                            ...  \n",
              "12334                      그동안 일을 꾸준히 해서 숙련도가 좋겠지?  \n",
              "12335  당구장에서 알바하는데 아저씨들이 나중에 밥한끼사준다면서 번호알려달라고 그래;;  \n",
              "12336               ㅠㅠ눈빛도 완전 그윽하게 쳐다보는데 그만둘까봐 그냥..  \n",
              "12337                     근데 누구냐니까 다른 남자인 친구로 속이더라  \n",
              "12338                         왜그래.. 너도 누군가에겐 엄친아라고  \n",
              "\n",
              "[12339 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n41GcFxjAANy"
      },
      "outputs": [],
      "source": [
        "data = data.sample(frac=1,random_state=43)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2W80sBFrXphQ"
      },
      "outputs": [],
      "source": [
        "spliter = int(len(data)*0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z8hWS7aZXphR"
      },
      "outputs": [],
      "source": [
        "train_df = data.iloc[:spliter,:]\n",
        "dev_df = data.iloc[spliter:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8lXPk75brqdK",
        "outputId": "f5401fa7-9cd6-49a0-e335-d812fd296ab6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e340ae97-9dde-4f5d-ae42-ee6bf770834e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masked</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12012</th>\n",
              "      <td>##면 여자 다고?</td>\n",
              "      <td>바이면 남자 여자 다 좋아한다고?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7675</th>\n",
              "      <td>사람이었어?</td>\n",
              "      <td>[UNK] 남편은 뭐하는 사람이었어?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5326</th>\n",
              "      <td>ㅋㅋ 게야</td>\n",
              "      <td>ㅋㅋ 그래도 잘생긴 게 최고야</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7621</th>\n",
              "      <td>NaN</td>\n",
              "      <td>당연히 결혼해야지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8923</th>\n",
              "      <td>전쟁도 없고 질병도 어느 정도는되고 말이야</td>\n",
              "      <td>전쟁도 없고 질병도 어느 정도는 해결되고 말이야</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11899</th>\n",
              "      <td>새이나 다름 없어!</td>\n",
              "      <td>거의 새상품이나 다름 없댔어!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2430</th>\n",
              "      <td>NaN</td>\n",
              "      <td>네가 이해해라</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11265</th>\n",
              "      <td>다리에 들어가</td>\n",
              "      <td>다리에 힘이 많이 들어가네</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7676</th>\n",
              "      <td>NaN</td>\n",
              "      <td>정권교체만이 답이다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9193</th>\n",
              "      <td>끼리끼리 말 어떻게?</td>\n",
              "      <td>친구는 끼리끼리라는 말 어떻게 생각해?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9871 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e340ae97-9dde-4f5d-ae42-ee6bf770834e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e340ae97-9dde-4f5d-ae42-ee6bf770834e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e340ae97-9dde-4f5d-ae42-ee6bf770834e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        masked                    original\n",
              "12012               ##면 여자 다고?          바이면 남자 여자 다 좋아한다고?\n",
              "7675                    사람이었어?        [UNK] 남편은 뭐하는 사람이었어?\n",
              "5326                     ㅋㅋ 게야            ㅋㅋ 그래도 잘생긴 게 최고야\n",
              "7621                       NaN                   당연히 결혼해야지\n",
              "8923   전쟁도 없고 질병도 어느 정도는되고 말이야  전쟁도 없고 질병도 어느 정도는 해결되고 말이야\n",
              "...                        ...                         ...\n",
              "11899               새이나 다름 없어!            거의 새상품이나 다름 없댔어!\n",
              "2430                       NaN                     네가 이해해라\n",
              "11265                  다리에 들어가              다리에 힘이 많이 들어가네\n",
              "7676                       NaN                  정권교체만이 답이다\n",
              "9193               끼리끼리 말 어떻게?       친구는 끼리끼리라는 말 어떻게 생각해?\n",
              "\n",
              "[9871 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IpEj62fGXphR",
        "outputId": "ddf7a5fd-9264-4305-853b-0f27a75b60dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-39951170-cd03-4f8e-9282-b9102d392399\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masked</th>\n",
              "      <th>original</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>수를 저 정권을 보낼 수</td>\n",
              "      <td>무슨 수를 써야 저 정권을 보낼 수 있는거야</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11322</th>\n",
              "      <td>김치는 내가 먹을 모르는데 옆에서 냄새 풍기면 진짜 별로임</td>\n",
              "      <td>김치는 내가 먹을 땐 모르는데, 옆에서 냄새 풍기면 진짜 별로임</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3281</th>\n",
              "      <td>NaN</td>\n",
              "      <td>너 미쳤어?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11309</th>\n",
              "      <td>사람 배구 선수 아냐</td>\n",
              "      <td>저 사람 그 배구 선수 아냐?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>조선족은 우리나라 투표 수 있나?</td>\n",
              "      <td>조선족은 우리나라 대통령 투표할 수 있나?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064</th>\n",
              "      <td>애가? 울린 애가 거지</td>\n",
              "      <td>운 애가 잘못이냐? 울린 애가 잘못한 거지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10517</th>\n",
              "      <td>에이 늙 않았</td>\n",
              "      <td>에이 그정도로 늙지는 않았어</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7985</th>\n",
              "      <td>##서 [UNK] 도 보이고 [UNK] 도 보이네</td>\n",
              "      <td>과거 사진에서 [UNK]도 보이고 [UNK]도 보이네</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2303</th>\n",
              "      <td>##만큼는 것도</td>\n",
              "      <td>노력한만큼 돌아오는 것도 없어</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3392</th>\n",
              "      <td>세 다 그래서부턴 걸러</td>\n",
              "      <td>세명 다 그래서 이제부턴 걸러</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2468 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39951170-cd03-4f8e-9282-b9102d392399')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39951170-cd03-4f8e-9282-b9102d392399 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39951170-cd03-4f8e-9282-b9102d392399');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 masked                             original\n",
              "1399                      수를 저 정권을 보낼 수             무슨 수를 써야 저 정권을 보낼 수 있는거야\n",
              "11322  김치는 내가 먹을 모르는데 옆에서 냄새 풍기면 진짜 별로임  김치는 내가 먹을 땐 모르는데, 옆에서 냄새 풍기면 진짜 별로임\n",
              "3281                                NaN                               너 미쳤어?\n",
              "11309                       사람 배구 선수 아냐                     저 사람 그 배구 선수 아냐?\n",
              "5105                 조선족은 우리나라 투표 수 있나?              조선족은 우리나라 대통령 투표할 수 있나?\n",
              "...                                 ...                                  ...\n",
              "2064                       애가? 울린 애가 거지              운 애가 잘못이냐? 울린 애가 잘못한 거지\n",
              "10517                           에이 늙 않았                      에이 그정도로 늙지는 않았어\n",
              "7985        ##서 [UNK] 도 보이고 [UNK] 도 보이네        과거 사진에서 [UNK]도 보이고 [UNK]도 보이네\n",
              "2303                           ##만큼는 것도                     노력한만큼 돌아오는 것도 없어\n",
              "3392                       세 다 그래서부턴 걸러                     세명 다 그래서 이제부턴 걸러\n",
              "\n",
              "[2468 rows x 2 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1IQAwiKYL5an"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_data = Dataset.from_pandas(train_df)\n",
        "dev_data = Dataset.from_pandas(dev_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OOs6u0ce9Lfc",
        "outputId": "5e714326-65bc-4a88-8b89-23446df2d151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['masked', 'original', '__index_level_0__'],\n",
              "    num_rows: 9871\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aeS7YJMf5z7"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v_NBLLqYf4bK"
      },
      "outputs": [],
      "source": [
        "model_name = 'skt/kogpt2-base-v2'\n",
        "max_length = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g8SKTyaIgE1X"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "                                          pad_token='<pad>', mask_token='<mask>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0Nd_A8L4mCqW"
      },
      "outputs": [],
      "source": [
        "def tokenizeWithLabel(data):\n",
        "    tokenized_datas = tokenizer(\n",
        "        f\"<unused0> <unused1> {data['masked']} <unused2> {data['original']} <unused3>\",\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    tokenized_datas['labels']=tokenized_datas[\"input_ids\"]\n",
        "    return tokenized_datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "838581ec9937488694eaa6312ff74ff1",
            "21e95ce778594d598c95b6d272d9aef6",
            "0c88ace3fe7f487aba120265c493f4e7",
            "7491c1cae88647cfbc40d71d108f7111",
            "2b4bcea2e171405e9570707ed3a804fb",
            "cab6fae0e79f45e8b2e99a1153179ac7",
            "19f4846aae2142b7a8a08f99b8b54c45",
            "179c4ff1e145423ba937903b2eb6b437",
            "64f3068b70264f40ad88cc30c832a0f1",
            "a943c5d00b704ee58d8137382fbd92ee",
            "995369f9d3364c0e8cf1aaf1f4125ec9",
            "5e6cd94cafc84074b1d2f65767c7e50a",
            "11b2b7067c844d69a602186a745f3921",
            "6bf4ccaf51dc42b298bf1f280931e093",
            "516e1f7d67904bda94e1158184f9b5f2",
            "7a33976b16c04c6fb9a93d8dac90e5aa",
            "c75da69892bd4041a0728a19919b376a",
            "c1825048602448318db5898cb0f7b8ed",
            "7c68dfe6ce854122bffbd3111c4c30d7",
            "ccc69b38e43444fb94b6aac2607ee60a",
            "9a21eaf223714576a1e3272baaa88066",
            "2e80042df92640eb966abbfc99b9a03d"
          ]
        },
        "id": "fuE7kI5VnxMU",
        "outputId": "096e5e46-e9bd-42f5-f098-721f5e1678f0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "838581ec9937488694eaa6312ff74ff1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9871 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e6cd94cafc84074b1d2f65767c7e50a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2468 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_tokenized_datasets = train_data.map(tokenizeWithLabel, remove_columns=train_data.column_names)\n",
        "dev_tokenized_datasets = dev_data.map(tokenizeWithLabel, remove_columns=dev_data.column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwL6IDroywR1"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8WA4EmB9j7WO"
      },
      "outputs": [],
      "source": [
        "sweep_configuration = {\n",
        "    'method': 'grid',\n",
        "    'name': 'sweep',\n",
        "    'metric': {'goal': 'minimize', 'name': 'eval/loss'},\n",
        "    'parameters': \n",
        "    {\n",
        "        'batch_size': {'values': [256]},\n",
        "        'epochs': {'values': [10]},\n",
        "        'lr': {'values': [1e-5]},\n",
        "        'scheduler': {'values': ['linear', 'cosine', 'constant']}\n",
        "     }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oivay0vN7GbZ"
      },
      "outputs": [],
      "source": [
        "max_batch_size = 32\n",
        "def train():\n",
        "    torch.cuda.empty_cache()\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    grouped_params = model.parameters()\n",
        "    run = wandb.init(config=sweep_configuration, entity=\"groom2team\")\n",
        "    batch_size = wandb.config.batch_size if wandb.config.batch_size < max_batch_size else max_batch_size\n",
        "    gradient_accumulation_steps= wandb.config.batch_size // max_batch_size\n",
        "    epochs = wandb.config.epochs\n",
        "    total_steps = int(len(train_tokenized_datasets)/wandb.config.batch_size*epochs)\n",
        "    learning_rate = wandb.config.lr\n",
        "    data_collator = default_data_collator\n",
        "    grouped_params = model.parameters()\n",
        "    optimizer=AdamW(grouped_params, lr=learning_rate)\n",
        "    scheduler_type = wandb.config.scheduler\n",
        "    if scheduler_type == 'linear':\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,\n",
        "                                                    num_warmup_steps=0,\n",
        "                                                    num_training_steps=total_steps)\n",
        "    elif scheduler_type == 'cosine':\n",
        "        scheduler=get_cosine_schedule_with_warmup(optimizer=optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)\n",
        "    elif scheduler_type == 'constant':\n",
        "        scheduler=get_constant_schedule(optimizer=optimizer)\n",
        "    optimizers = optimizer, scheduler\n",
        "    args = TrainingArguments(\n",
        "        f\"{model_name}-finetuned\",\n",
        "        evaluation_strategy = \"steps\",\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "        report_to=\"wandb\",\n",
        "        run_name=\"utopia\",\n",
        "        logging_steps = total_steps//200,\n",
        "        eval_steps = total_steps//100,\n",
        "        save_steps = total_steps//100,\n",
        "        weight_decay=0.0,\n",
        "        save_total_limit = 2,\n",
        "        load_best_model_at_end=True\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model,\n",
        "        args,\n",
        "        train_dataset=train_tokenized_datasets,\n",
        "        eval_dataset=dev_tokenized_datasets,\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "        callbacks = [EarlyStoppingCallback(early_stopping_patience=10)],\n",
        "        optimizers=optimizers\n",
        "    )\n",
        "    trainer.train()# train 하고\n",
        "    trainer.save_model(output_dir= 'pytorch_finetuned') # trainer에서 실행된 model save\n",
        "    artifact = wandb.Artifact(name='pytorch_finetuned', type='model') # wandb에 해당 모델 version 관리.\n",
        "    artifact.add_dir('pytorch_finetuned', name='best_model_at_end')\n",
        "    run.log_artifact(artifact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2RO_F3XnkEkn",
        "outputId": "612e8bfd-2ffe-45a4-cb1b-66e5b8e17df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 7duagugh\n",
            "Sweep URL: https://wandb.ai/groom2team/pj3_gen_gpt2/sweeps/7duagugh\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep=sweep_configuration, project='pj3_generater_gpt2', entity='groom2team')\n",
        "count = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8747
        },
        "id": "fzzJxKpQkML3",
        "outputId": "391ebdd5-1177-4f0b-eddb-dbb773f9f4db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e2wdqyei with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: linear\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmjchoi\u001b[0m (\u001b[33mgroom2team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221028_093158-e2wdqyei</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/groom2team/pj3_gen_gpt2/runs/e2wdqyei\" target=\"_blank\">lyric-sweep-1</a></strong> to <a href=\"https://wandb.ai/groom2team/pj3_gen_gpt2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/groom2team/pj3_gen_gpt2/sweeps/7duagugh\" target=\"_blank\">https://wandb.ai/groom2team/pj3_gen_gpt2/sweeps/7duagugh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 9871\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 380\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='131' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [131/380 19:54 < 38:24, 0.11 it/s, Epoch 3.41/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>12.258100</td>\n",
              "      <td>10.326203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>6.507300</td>\n",
              "      <td>3.138832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.681100</td>\n",
              "      <td>0.759090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.717600</td>\n",
              "      <td>0.675427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.603300</td>\n",
              "      <td>0.558822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.538300</td>\n",
              "      <td>0.493798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.485600</td>\n",
              "      <td>0.451489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.449600</td>\n",
              "      <td>0.408962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.403100</td>\n",
              "      <td>0.367910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.354200</td>\n",
              "      <td>0.331047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.323100</td>\n",
              "      <td>0.306649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.315200</td>\n",
              "      <td>0.291529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.496400</td>\n",
              "      <td>0.283858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.293200</td>\n",
              "      <td>0.279491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.284200</td>\n",
              "      <td>0.276532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.283800</td>\n",
              "      <td>0.273949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.282300</td>\n",
              "      <td>0.271618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.280100</td>\n",
              "      <td>0.269493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.271400</td>\n",
              "      <td>0.267675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.276400</td>\n",
              "      <td>0.266182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.272700</td>\n",
              "      <td>0.264577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.280900</td>\n",
              "      <td>0.263036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.277700</td>\n",
              "      <td>0.261806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.268300</td>\n",
              "      <td>0.260945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.263500</td>\n",
              "      <td>0.260194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.271800</td>\n",
              "      <td>0.259137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.261500</td>\n",
              "      <td>0.258190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.258200</td>\n",
              "      <td>0.257558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.261700</td>\n",
              "      <td>0.257016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.262400</td>\n",
              "      <td>0.256388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.265700</td>\n",
              "      <td>0.255678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.268400</td>\n",
              "      <td>0.255144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.262000</td>\n",
              "      <td>0.254647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.256500</td>\n",
              "      <td>0.254192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.252500</td>\n",
              "      <td>0.253839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.249600</td>\n",
              "      <td>0.253360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.257600</td>\n",
              "      <td>0.252856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.266700</td>\n",
              "      <td>0.252433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.256200</td>\n",
              "      <td>0.252142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.256100</td>\n",
              "      <td>0.251850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.265000</td>\n",
              "      <td>0.251320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.258200</td>\n",
              "      <td>0.250922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.250300</td>\n",
              "      <td>0.250661</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-3\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-3/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-3/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-3/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-3/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-9] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-6\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-6/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-6/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-6/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-6/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-12] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-9\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-9/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-9/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-9/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-9/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-3] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-12\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-12/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-12/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-12/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-12/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-6] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-15\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-15/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-15/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-15/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-15/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-9] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-18\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-18/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-18/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-12] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-21\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-21/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-21/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-21/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-21/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-15] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-24\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-24/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-24/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-24/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-24/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-18] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-27\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-27/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-27/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-27/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-27/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-21] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-30\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-30/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-30/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-30/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-30/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-24] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-33\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-33/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-33/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-33/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-33/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-27] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-36\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-36/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-36/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-30] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-39\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-39/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-39/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-39/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-39/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-33] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-42\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-42/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-42/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-42/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-42/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-45\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-45/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-45/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-45/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-45/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-39] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-48\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-48/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-48/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-48/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-48/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-42] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-51\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-51/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-51/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-51/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-51/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-45] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-54\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-54/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-48] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-57\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-57/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-57/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-57/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-57/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-51] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-60\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-60/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-60/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-60/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-60/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-63\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-63/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-63/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-63/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-63/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-57] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-66\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-66/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-66/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-66/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-66/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-60] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-69\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-69/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-69/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-69/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-69/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-63] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-72\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-72/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-66] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-75\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-75/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-75/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-75/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-75/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-69] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-78\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-78/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-78/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-78/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-78/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-81\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-81/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-81/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-81/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-81/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-75] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-84\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-84/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-84/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-84/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-84/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-78] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-87\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-87/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-87/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-87/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-87/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-81] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-90\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-90/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-84] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-93\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-93/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-93/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-93/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-93/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-87] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-96\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-96/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-96/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-96/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-96/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-99\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-99/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-99/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-99/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-99/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-93] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-102\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-102/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-102/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-102/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-102/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-96] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-105\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-105/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-105/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-105/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-105/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-99] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-108\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-108/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-102] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-111\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-111/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-111/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-111/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-111/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-105] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-114\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-114/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-114/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-114/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-114/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-117\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-117/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-117/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-117/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-117/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-111] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-120\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-120/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-120/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-120/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-120/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-114] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-123\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-123/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-123/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-123/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-123/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-117] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-126\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-126/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-120] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2468\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to skt/kogpt2-base-v2-finetuned/checkpoint-129\n",
            "Configuration saved in skt/kogpt2-base-v2-finetuned/checkpoint-129/config.json\n",
            "Model weights saved in skt/kogpt2-base-v2-finetuned/checkpoint-129/pytorch_model.bin\n",
            "tokenizer config file saved in skt/kogpt2-base-v2-finetuned/checkpoint-129/tokenizer_config.json\n",
            "Special tokens file saved in skt/kogpt2-base-v2-finetuned/checkpoint-129/special_tokens_map.json\n",
            "Deleting older checkpoint [skt/kogpt2-base-v2-finetuned/checkpoint-123] due to args.save_total_limit\n"
          ]
        }
      ],
      "source": [
        "wandb.agent(sweep_id, function=train, count=count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJXOUNOCqn91"
      },
      "outputs": [],
      "source": [
        "wandb.finish() # wandb 종료"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bO5N5W7wbTyL",
        "58AlIH3hbYk2",
        "0aeS7YJMf5z7"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('ML')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "68907262db0d5b754134764abe59bf5c8676f176bc4cefb4b73cecf4416d77ae"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c88ace3fe7f487aba120265c493f4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_179c4ff1e145423ba937903b2eb6b437",
            "max": 9871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64f3068b70264f40ad88cc30c832a0f1",
            "value": 9871
          }
        },
        "11b2b7067c844d69a602186a745f3921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c75da69892bd4041a0728a19919b376a",
            "placeholder": "​",
            "style": "IPY_MODEL_c1825048602448318db5898cb0f7b8ed",
            "value": "100%"
          }
        },
        "179c4ff1e145423ba937903b2eb6b437": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f4846aae2142b7a8a08f99b8b54c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21e95ce778594d598c95b6d272d9aef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab6fae0e79f45e8b2e99a1153179ac7",
            "placeholder": "​",
            "style": "IPY_MODEL_19f4846aae2142b7a8a08f99b8b54c45",
            "value": "100%"
          }
        },
        "2b4bcea2e171405e9570707ed3a804fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e80042df92640eb966abbfc99b9a03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "516e1f7d67904bda94e1158184f9b5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a21eaf223714576a1e3272baaa88066",
            "placeholder": "​",
            "style": "IPY_MODEL_2e80042df92640eb966abbfc99b9a03d",
            "value": " 2468/2468 [00:00&lt;00:00, 2353.20ex/s]"
          }
        },
        "5e6cd94cafc84074b1d2f65767c7e50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11b2b7067c844d69a602186a745f3921",
              "IPY_MODEL_6bf4ccaf51dc42b298bf1f280931e093",
              "IPY_MODEL_516e1f7d67904bda94e1158184f9b5f2"
            ],
            "layout": "IPY_MODEL_7a33976b16c04c6fb9a93d8dac90e5aa"
          }
        },
        "64f3068b70264f40ad88cc30c832a0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bf4ccaf51dc42b298bf1f280931e093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c68dfe6ce854122bffbd3111c4c30d7",
            "max": 2468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccc69b38e43444fb94b6aac2607ee60a",
            "value": 2468
          }
        },
        "7491c1cae88647cfbc40d71d108f7111": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a943c5d00b704ee58d8137382fbd92ee",
            "placeholder": "​",
            "style": "IPY_MODEL_995369f9d3364c0e8cf1aaf1f4125ec9",
            "value": " 9871/9871 [00:03&lt;00:00, 2773.55ex/s]"
          }
        },
        "7a33976b16c04c6fb9a93d8dac90e5aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c68dfe6ce854122bffbd3111c4c30d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838581ec9937488694eaa6312ff74ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21e95ce778594d598c95b6d272d9aef6",
              "IPY_MODEL_0c88ace3fe7f487aba120265c493f4e7",
              "IPY_MODEL_7491c1cae88647cfbc40d71d108f7111"
            ],
            "layout": "IPY_MODEL_2b4bcea2e171405e9570707ed3a804fb"
          }
        },
        "995369f9d3364c0e8cf1aaf1f4125ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a21eaf223714576a1e3272baaa88066": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a943c5d00b704ee58d8137382fbd92ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1825048602448318db5898cb0f7b8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c75da69892bd4041a0728a19919b376a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab6fae0e79f45e8b2e99a1153179ac7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc69b38e43444fb94b6aac2607ee60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
